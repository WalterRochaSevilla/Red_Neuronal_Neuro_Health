{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "1-n-RM-jau7U",
    "outputId": "6bd7270f-7e9f-429d-8c90-23b6dfe6719b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d-O--9dua1A2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diario_emociones.csv\")\n",
    "\n",
    "# Balancear clases por sobremuestreo\n",
    "dfs = []\n",
    "for emocion in df[\"emocion\"].unique():\n",
    "    subset = df[df[\"emocion\"] == emocion]\n",
    "    dfs.append(resample(subset, \n",
    "                      replace=True, \n",
    "                      n_samples=500,  # Ajustar según necesidad\n",
    "                      random_state=42))\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "66USbVjua3JY"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    doc = nlp(texto.lower())\n",
    "    tokens = [\n",
    "        token.lemma_ \n",
    "        for token in doc \n",
    "        if not token.is_stop \n",
    "        and not token.is_punct\n",
    "        and token.is_alpha\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"texto_limpio\"] = df[\"texto\"].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OX17eewza6Aa"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    ngram_range=(1, 2),  # Bigramas\n",
    "    min_df=5,            # Ignorar términos raros\n",
    "    max_df=0.9          # Ignorar términos muy comunes\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"texto_limpio\"]).toarray()\n",
    "\n",
    "# Codificación de emociones\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df[\"emocion\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OrWBfQLXa7sC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walte\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(\n",
    "    256, \n",
    "    input_shape=(X.shape[1],),\n",
    "    activation='relu',\n",
    "    kernel_regularizer=l2(0.02),\n",
    "    activity_regularizer=l2(0.01)\n",
    "))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(\n",
    "    128,\n",
    "    activation='relu',\n",
    "    kernel_regularizer=l2(0.01))\n",
    ")\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(\n",
    "    len(label_encoder.classes_), \n",
    "    activation='softmax'\n",
    "))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "r8MWtHyea9Mz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.2442 - loss: 8.0066 - val_accuracy: 0.6300 - val_loss: 4.5277\n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4122 - loss: 3.8966 - val_accuracy: 0.6200 - val_loss: 2.5461\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4440 - loss: 2.3248 - val_accuracy: 0.9060 - val_loss: 1.8603\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6848 - loss: 1.7766 - val_accuracy: 0.9900 - val_loss: 1.5508\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7800 - loss: 1.4977 - val_accuracy: 1.0000 - val_loss: 1.2146\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8904 - loss: 1.1911 - val_accuracy: 1.0000 - val_loss: 0.9369\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9538 - loss: 1.0188 - val_accuracy: 1.0000 - val_loss: 0.7889\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9834 - loss: 0.8928 - val_accuracy: 1.0000 - val_loss: 0.7125\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.8487 - val_accuracy: 1.0000 - val_loss: 0.6625\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.7939 - val_accuracy: 1.0000 - val_loss: 0.6282\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.7663 - val_accuracy: 1.0000 - val_loss: 0.5983\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9764 - loss: 0.7386 - val_accuracy: 1.0000 - val_loss: 0.5735\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.7135 - val_accuracy: 1.0000 - val_loss: 0.5534\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.6846 - val_accuracy: 1.0000 - val_loss: 0.5369\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9816 - loss: 0.6711 - val_accuracy: 1.0000 - val_loss: 0.5213\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.6502 - val_accuracy: 1.0000 - val_loss: 0.5063\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.6402 - val_accuracy: 1.0000 - val_loss: 0.4977\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.6292 - val_accuracy: 1.0000 - val_loss: 0.4834\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.6144 - val_accuracy: 1.0000 - val_loss: 0.4762\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.5901 - val_accuracy: 1.0000 - val_loss: 0.4637\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9838 - loss: 0.5963 - val_accuracy: 1.0000 - val_loss: 0.4559\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9847 - loss: 0.5787 - val_accuracy: 1.0000 - val_loss: 0.4463\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.5781 - val_accuracy: 1.0000 - val_loss: 0.4425\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.5671 - val_accuracy: 1.0000 - val_loss: 0.4308\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.5525 - val_accuracy: 1.0000 - val_loss: 0.4278\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.5373 - val_accuracy: 1.0000 - val_loss: 0.4175\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9866 - loss: 0.5416 - val_accuracy: 1.0000 - val_loss: 0.4137\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.5321 - val_accuracy: 1.0000 - val_loss: 0.4057\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9917 - loss: 0.5175 - val_accuracy: 1.0000 - val_loss: 0.4012\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9884 - loss: 0.5205 - val_accuracy: 1.0000 - val_loss: 0.3995\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9835 - loss: 0.5298 - val_accuracy: 1.0000 - val_loss: 0.3918\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.5072 - val_accuracy: 1.0000 - val_loss: 0.3880\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.4960 - val_accuracy: 1.0000 - val_loss: 0.3819\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.4857 - val_accuracy: 1.0000 - val_loss: 0.3747\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9857 - loss: 0.4865 - val_accuracy: 1.0000 - val_loss: 0.3714\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.4852 - val_accuracy: 1.0000 - val_loss: 0.3692\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.4852 - val_accuracy: 1.0000 - val_loss: 0.3643\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.4684 - val_accuracy: 1.0000 - val_loss: 0.3597\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.4632 - val_accuracy: 1.0000 - val_loss: 0.3584\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.4634 - val_accuracy: 1.0000 - val_loss: 0.3536\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.4673 - val_accuracy: 1.0000 - val_loss: 0.3510\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9930 - loss: 0.4618 - val_accuracy: 1.0000 - val_loss: 0.3459\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.4585 - val_accuracy: 1.0000 - val_loss: 0.3412\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.4503 - val_accuracy: 1.0000 - val_loss: 0.3419\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.4393 - val_accuracy: 1.0000 - val_loss: 0.3338\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.4479 - val_accuracy: 1.0000 - val_loss: 0.3351\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9945 - loss: 0.4328 - val_accuracy: 1.0000 - val_loss: 0.3327\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.4457 - val_accuracy: 1.0000 - val_loss: 0.3283\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.4325 - val_accuracy: 1.0000 - val_loss: 0.3262\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.4205 - val_accuracy: 1.0000 - val_loss: 0.3201\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.4189 - val_accuracy: 1.0000 - val_loss: 0.3200\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.4253 - val_accuracy: 1.0000 - val_loss: 0.3184\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9843 - loss: 0.4197 - val_accuracy: 1.0000 - val_loss: 0.3157\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.4161 - val_accuracy: 1.0000 - val_loss: 0.3124\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9935 - loss: 0.4130 - val_accuracy: 1.0000 - val_loss: 0.3116\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.3981 - val_accuracy: 1.0000 - val_loss: 0.3060\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9888 - loss: 0.3986 - val_accuracy: 1.0000 - val_loss: 0.3073\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9924 - loss: 0.3905 - val_accuracy: 1.0000 - val_loss: 0.3013\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9957 - loss: 0.3961 - val_accuracy: 1.0000 - val_loss: 0.3043\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9904 - loss: 0.3991 - val_accuracy: 1.0000 - val_loss: 0.2995\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9943 - loss: 0.3983 - val_accuracy: 1.0000 - val_loss: 0.2973\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9927 - loss: 0.3932 - val_accuracy: 1.0000 - val_loss: 0.2959\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9942 - loss: 0.3808 - val_accuracy: 1.0000 - val_loss: 0.2935\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9946 - loss: 0.3838 - val_accuracy: 1.0000 - val_loss: 0.2916\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.3831 - val_accuracy: 1.0000 - val_loss: 0.2901\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.3793 - val_accuracy: 1.0000 - val_loss: 0.2898\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.3790 - val_accuracy: 1.0000 - val_loss: 0.2871\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.3864 - val_accuracy: 1.0000 - val_loss: 0.2843\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.3763 - val_accuracy: 1.0000 - val_loss: 0.2811\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9938 - loss: 0.3628 - val_accuracy: 1.0000 - val_loss: 0.2821\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.3637 - val_accuracy: 1.0000 - val_loss: 0.2791\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.3751 - val_accuracy: 1.0000 - val_loss: 0.2811\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.3750 - val_accuracy: 1.0000 - val_loss: 0.2751\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.3753 - val_accuracy: 1.0000 - val_loss: 0.2773\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.3721 - val_accuracy: 1.0000 - val_loss: 0.2708\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.3685 - val_accuracy: 1.0000 - val_loss: 0.2725\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9940 - loss: 0.3605 - val_accuracy: 1.0000 - val_loss: 0.2686\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.3605 - val_accuracy: 1.0000 - val_loss: 0.2684\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.3586 - val_accuracy: 1.0000 - val_loss: 0.2622\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.3579 - val_accuracy: 1.0000 - val_loss: 0.2686\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.3599 - val_accuracy: 1.0000 - val_loss: 0.2633\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.3491 - val_accuracy: 1.0000 - val_loss: 0.2625\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.3502 - val_accuracy: 1.0000 - val_loss: 0.2601\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9821 - loss: 0.3624 - val_accuracy: 1.0000 - val_loss: 0.2595\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.3477 - val_accuracy: 1.0000 - val_loss: 0.2551\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.3363 - val_accuracy: 1.0000 - val_loss: 0.2547\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.3442 - val_accuracy: 1.0000 - val_loss: 0.2540\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.3465 - val_accuracy: 1.0000 - val_loss: 0.2543\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.3475 - val_accuracy: 1.0000 - val_loss: 0.2556\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.3433 - val_accuracy: 1.0000 - val_loss: 0.2543\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.3431 - val_accuracy: 1.0000 - val_loss: 0.2490\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.3431 - val_accuracy: 1.0000 - val_loss: 0.2505\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.3427 - val_accuracy: 1.0000 - val_loss: 0.2481\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.3338 - val_accuracy: 1.0000 - val_loss: 0.2481\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9947 - loss: 0.3317 - val_accuracy: 1.0000 - val_loss: 0.2423\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.3336 - val_accuracy: 1.0000 - val_loss: 0.2452\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 0.3406 - val_accuracy: 1.0000 - val_loss: 0.2446\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9956 - loss: 0.3228 - val_accuracy: 1.0000 - val_loss: 0.2400\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.3206 - val_accuracy: 1.0000 - val_loss: 0.2412\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9924 - loss: 0.3182 - val_accuracy: 1.0000 - val_loss: 0.2394\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ovqUF7-Ka-r1"
   },
   "outputs": [],
   "source": [
    "def predecir_emocion(texto, umbral_confianza=0.65):\n",
    "    texto_limpio = limpiar_texto(texto)\n",
    "    texto_vector = vectorizer.transform([texto_limpio]).toarray()\n",
    "    prediccion = model.predict(texto_vector, verbose=0)\n",
    "    \n",
    "    if np.max(prediccion) < umbral_confianza:\n",
    "        return \"indefinido\", np.max(prediccion)\n",
    "    \n",
    "    return label_encoder.inverse_transform([np.argmax(prediccion)])[0], np.max(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_respuesta(texto):\n",
    "    emocion, confianza = predecir_emocion(texto)\n",
    "    \n",
    "    recursos = {\n",
    "        \"tristeza\": {\n",
    "            \"mensaje\": \"🔵 Pareces sentir tristeza. Te recomiendo:\",\n",
    "            \"acciones\": [\n",
    "                \"Meditación guiada 'Alivio emocional' (10 min)\",\n",
    "                \"Ejercicio: Escribe una carta para liberar emociones\"\n",
    "            ]\n",
    "        },\n",
    "        \"ansiedad\": {\n",
    "            \"mensaje\": \"🟠 Detecto señales de ansiedad. Prueba:\",\n",
    "            \"acciones\": [\n",
    "                \"Técnica de respiración 4-7-8 (instrucciones)\",\n",
    "                \"Ejercicio de grounding: 5-4-3-2-1\"\n",
    "            ]\n",
    "        },\n",
    "        \"estrés\": {\n",
    "            \"mensaje\": \"🟢 Sugerencias para manejar el estrés:\",\n",
    "            \"acciones\": [\n",
    "                \"Meditación 'Libera tensiones' (15 min)\",\n",
    "                \"Prioriza tareas con matriz Eisenhower\"\n",
    "            ]\n",
    "        },\n",
    "        \"enojo\": {\n",
    "            \"mensaje\": \"🔴 Detecto frustración. Intenta:\",\n",
    "            \"acciones\": [\n",
    "                \"Ejercicio físico de alta intensidad\",\n",
    "                \"Técnica de pausa consciente de 5 minutos\"\n",
    "            ]\n",
    "        },\n",
    "        \"felicidad\": {\n",
    "            \"mensaje\": \"🟡 ¡Me alegra verte así! Mantén esto:\",\n",
    "            \"acciones\": [\n",
    "                \"Registra este momento en tu diario positivo\",\n",
    "                \"Comparte tu estado con alguien especial\"\n",
    "            ]\n",
    "        },\n",
    "        \"indefinido\": {\n",
    "            \"mensaje\": \"⚪️ Necesito entenderte mejor. ¿Podrías:\",\n",
    "            \"acciones\": [\n",
    "                \"Describir cómo te sientes con más detalle?\",\n",
    "                \"Contarme qué ha pasado recientemente?\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    respuesta = recursos.get(emocion, recursos[\"indefinido\"])\n",
    "    return (\n",
    "        f\"{respuesta['mensaje']}\\n\" + \n",
    "        \"\\n\".join([f\"- {accion}\" for accion in respuesta['acciones']]) + \n",
    "        f\"\\n\\nConfianza del modelo: {confianza:.2%}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FdZpptV0bA4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧑 Usuario: No tengo ganas de salir de la cama hoy\n",
      "🤖 Chatbot:\n",
      "⚪️ Necesito entenderte mejor. ¿Podrías:\n",
      "- Describir cómo te sientes con más detalle?\n",
      "- Contarme qué ha pasado recientemente?\n",
      "\n",
      "Confianza del modelo: 63.09%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "🧑 Usuario: Estoy harto de las reuniones inútiles\n",
      "🤖 Chatbot:\n",
      "🔴 Detecto frustración. Intenta:\n",
      "- Ejercicio físico de alta intensidad\n",
      "- Técnica de pausa consciente de 5 minutos\n",
      "\n",
      "Confianza del modelo: 77.39%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "🧑 Usuario: Me palpita el corazón muy rápido\n",
      "🤖 Chatbot:\n",
      "⚪️ Necesito entenderte mejor. ¿Podrías:\n",
      "- Describir cómo te sientes con más detalle?\n",
      "- Contarme qué ha pasado recientemente?\n",
      "\n",
      "Confianza del modelo: 31.05%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "🧑 Usuario: Logré terminar todos mis pendientes a tiempo!\n",
      "🤖 Chatbot:\n",
      "⚪️ Necesito entenderte mejor. ¿Podrías:\n",
      "- Describir cómo te sientes con más detalle?\n",
      "- Contarme qué ha pasado recientemente?\n",
      "\n",
      "Confianza del modelo: 45.52%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "🧑 Usuario: El tráfico me hizo llegar tarde otra vez\n",
      "🤖 Chatbot:\n",
      "🟢 Sugerencias para manejar el estrés:\n",
      "- Meditación 'Libera tensiones' (15 min)\n",
      "- Prioriza tareas con matriz Eisenhower\n",
      "\n",
      "Confianza del modelo: 83.94%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    \"No tengo ganas de salir de la cama hoy\",\n",
    "    \"Estoy harto de las reuniones inútiles\",\n",
    "    \"Me palpita el corazón muy rápido\",\n",
    "    \"Logré terminar todos mis pendientes a tiempo!\",\n",
    "    \"El tráfico me hizo llegar tarde otra vez\"\n",
    "]\n",
    "\n",
    "for caso in test_cases:\n",
    "    print(f\"🧑 Usuario: {caso}\")\n",
    "    print(f\"🤖 Chatbot:\\n{chatbot_respuesta(caso)}\\n\")\n",
    "    print(\"―\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
