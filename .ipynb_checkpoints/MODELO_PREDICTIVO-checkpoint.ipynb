{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "1-n-RM-jau7U",
    "outputId": "6bd7270f-7e9f-429d-8c90-23b6dfe6719b"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'nlpaug'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mregularizers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m l2\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspacy\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnlpaug\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maugmenter\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mword\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnaw\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'nlpaug'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "import spacy\n",
    "import nlpaug.augmenter.word as naw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-O--9dua1A2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diario_emociones.csv\")\n",
    "\n",
    "# Aumentación de datos con NLP Aug\n",
    "def aumentar_datos(df, num_aug=3):\n",
    "    aug = naw.ContextualWordEmbsAug(\n",
    "        model_path='bert-base-multilingual-uncased',\n",
    "        action=\"substitute\",\n",
    "        aug_max=2\n",
    "    )\n",
    "    \n",
    "    nuevos_datos = []\n",
    "    for _, fila in df.iterrows():\n",
    "        for _ in range(num_aug):\n",
    "            texto_aug = aug.augment(fila[\"texto\"])\n",
    "            nuevos_datos.append({\n",
    "                \"fecha\": fila[\"fecha\"],\n",
    "                \"texto\": texto_aug,\n",
    "                \"emocion\": fila[\"emocion\"]\n",
    "            })\n",
    "    return pd.concat([df, pd.DataFrame(nuevos_datos)], ignore_index=True)\n",
    "\n",
    "df = aumentar_datos(df, num_aug=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "66USbVjua3JY"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    doc = nlp(texto.lower())\n",
    "    tokens = [\n",
    "        token.lemma_ \n",
    "        for token in doc \n",
    "        if not token.is_stop \n",
    "        and not token.is_punct\n",
    "        and token.is_alpha\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"texto_limpio\"] = df[\"texto\"].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OX17eewza6Aa"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    ngram_range=(1, 2),  # Considera bigramas\n",
    "    min_df=3,            # Ignora términos raros\n",
    "    max_df=0.85          # Ignora términos muy comunes\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"texto_limpio\"]).toarray()\n",
    "\n",
    "# Codificación de emociones\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df[\"emocion\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OrWBfQLXa7sC"
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(\n",
    "    128, \n",
    "    input_shape=(X.shape[1],),\n",
    "    activation='relu',\n",
    "    kernel_regularizer=l2(0.01)\n",
    "))\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(\n",
    "    64,\n",
    "    activation='relu',\n",
    "    kernel_regularizer=l2(0.005)\n",
    "))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(\n",
    "    len(label_encoder.classes_), \n",
    "    activation='softmax'\n",
    "))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r8MWtHyea9Mz"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y  # Mantiene distribución de clases\n",
    ")\n",
    "\n",
    "# Early stopping manual basado en val_loss\n",
    "best_val_loss = float('inf')\n",
    "patience = 3\n",
    "no_improve = 0\n",
    "\n",
    "for epoch in range(100):\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=32,\n",
    "        epochs=1,\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    current_val_loss = history.history['val_loss'][0]\n",
    "    \n",
    "    # Guardar mejor modelo\n",
    "    if current_val_loss < best_val_loss:\n",
    "        best_val_loss = current_val_loss\n",
    "        no_improve = 0\n",
    "        model.save(\"mejor_modelo.h5\")\n",
    "    else:\n",
    "        no_improve += 1\n",
    "    \n",
    "    if no_improve >= patience:\n",
    "        print(f\"Early stopping en época {epoch+1}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ovqUF7-Ka-r1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model(\"mejor_modelo.h5\")\n",
    "\n",
    "# Función mejorada de predicción\n",
    "def predecir_emocion(texto, umbral_confianza=0.7):\n",
    "    texto_limpio = limpiar_texto(texto)\n",
    "    texto_vector = vectorizer.transform([texto_limpio]).toarray()\n",
    "    prediccion = model.predict(texto_vector, verbose=0)\n",
    "    \n",
    "    if np.max(prediccion) < umbral_confianza:\n",
    "        return \"indefinido\"\n",
    "    \n",
    "    return label_encoder.inverse_transform([np.argmax(prediccion)])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_respuesta(texto):\n",
    "    emocion = predecir_emocion(texto)\n",
    "    \n",
    "    recursos = {\n",
    "        \"tristeza\": {\n",
    "            \"mensaje\": \"Parece que te sientes triste. Te recomiendo:\",\n",
    "            \"recursos\": [\n",
    "                \"Meditación guiada para la tristeza (15 min)\",\n",
    "                \"Ejercicio: Escribe 3 cosas que aprecies de ti mismo\"\n",
    "            ]\n",
    "        },\n",
    "        \"ansiedad\": {\n",
    "            \"mensaje\": \"Detecté ansiedad. Prueba estos recursos:\",\n",
    "            \"recursos\": [\n",
    "                \"Técnica de respiración 4-7-8\",\n",
    "                \"Ejercicio de grounding: Nombra 5 cosas que ves alrededor\"\n",
    "            ]\n",
    "        },\n",
    "        \"estrés\": {\n",
    "            \"mensaje\": \"Sugiero estos recursos para el estrés:\",\n",
    "            \"recursos\": [\n",
    "                \"Meditación de relajación muscular\",\n",
    "                \"Lista de priorización de tareas\"\n",
    "            ]\n",
    "        },\n",
    "        \"indefinido\": {\n",
    "            \"mensaje\": \"¿Puedes contarme más sobre cómo te sientes?\",\n",
    "            \"recursos\": []\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    respuesta = recursos.get(emocion, recursos[\"indefinido\"])\n",
    "    return f\"{respuesta['mensaje']}\\n\" + \"\\n\".join(respuesta['recursos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FdZpptV0bA4e"
   },
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    \"Tengo miedo de no cumplir con los plazos del trabajo\",\n",
    "    \"Mi pareja me hizo sentir muy mal hoy\",\n",
    "    \"Estoy feliz porque logré terminar mi proyecto\",\n",
    "    \"El ruido constante me está volviendo loco\"\n",
    "]\n",
    "\n",
    "for caso in test_cases:\n",
    "    print(f\"Usuario: {caso}\")\n",
    "    print(f\"Chatbot: {chatbot_respuesta(caso)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
