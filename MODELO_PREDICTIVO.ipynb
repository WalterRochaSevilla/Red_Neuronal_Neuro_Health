{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 365
    },
    "id": "1-n-RM-jau7U",
    "outputId": "6bd7270f-7e9f-429d-8c90-23b6dfe6719b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "d-O--9dua1A2"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"diario_emociones.csv\")\n",
    "\n",
    "# Balancear clases por sobremuestreo\n",
    "dfs = []\n",
    "for emocion in df[\"emocion\"].unique():\n",
    "    subset = df[df[\"emocion\"] == emocion]\n",
    "    dfs.append(resample(subset, \n",
    "                      replace=True, \n",
    "                      n_samples=500,  # Ajustar según necesidad\n",
    "                      random_state=42))\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "66USbVjua3JY"
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"es_core_news_sm\")\n",
    "\n",
    "def limpiar_texto(texto):\n",
    "    doc = nlp(texto.lower())\n",
    "    tokens = [\n",
    "        token.lemma_ \n",
    "        for token in doc \n",
    "        if not token.is_stop \n",
    "        and not token.is_punct\n",
    "        and token.is_alpha\n",
    "    ]\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "df[\"texto_limpio\"] = df[\"texto\"].apply(limpiar_texto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "OX17eewza6Aa"
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(\n",
    "    max_features=3000,\n",
    "    ngram_range=(1, 2),  # Bigramas\n",
    "    min_df=5,            # Ignorar términos raros\n",
    "    max_df=0.9          # Ignorar términos muy comunes\n",
    ")\n",
    "X = vectorizer.fit_transform(df[\"texto_limpio\"]).toarray()\n",
    "\n",
    "# Codificación de emociones\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df[\"emocion\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "OrWBfQLXa7sC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\walte\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(\n",
    "    256, \n",
    "    input_shape=(X.shape[1],),\n",
    "    activation='relu',\n",
    "    kernel_regularizer=l2(0.02),\n",
    "    activity_regularizer=l2(0.01)\n",
    "))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(\n",
    "    128,\n",
    "    activation='relu',\n",
    "    kernel_regularizer=l2(0.01))\n",
    ")\n",
    "model.add(Dropout(0.6))\n",
    "model.add(Dense(\n",
    "    len(label_encoder.classes_), \n",
    "    activation='softmax'\n",
    "))\n",
    "\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "r8MWtHyea9Mz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 13ms/step - accuracy: 0.2634 - loss: 8.1040 - val_accuracy: 0.8140 - val_loss: 4.5293\n",
      "Epoch 2/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.3901 - loss: 3.8867 - val_accuracy: 0.7640 - val_loss: 2.5254\n",
      "Epoch 3/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.4789 - loss: 2.3045 - val_accuracy: 0.9060 - val_loss: 1.8481\n",
      "Epoch 4/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6715 - loss: 1.7677 - val_accuracy: 1.0000 - val_loss: 1.5650\n",
      "Epoch 5/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7448 - loss: 1.5237 - val_accuracy: 1.0000 - val_loss: 1.2856\n",
      "Epoch 6/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8980 - loss: 1.2701 - val_accuracy: 1.0000 - val_loss: 1.0089\n",
      "Epoch 7/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9525 - loss: 1.0524 - val_accuracy: 1.0000 - val_loss: 0.8245\n",
      "Epoch 8/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9774 - loss: 0.9222 - val_accuracy: 1.0000 - val_loss: 0.7320\n",
      "Epoch 9/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9678 - loss: 0.8593 - val_accuracy: 1.0000 - val_loss: 0.6793\n",
      "Epoch 10/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9862 - loss: 0.7995 - val_accuracy: 1.0000 - val_loss: 0.6388\n",
      "Epoch 11/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9741 - loss: 0.7847 - val_accuracy: 1.0000 - val_loss: 0.6112\n",
      "Epoch 12/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.7524 - val_accuracy: 1.0000 - val_loss: 0.5847\n",
      "Epoch 13/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9774 - loss: 0.7356 - val_accuracy: 1.0000 - val_loss: 0.5657\n",
      "Epoch 14/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9673 - loss: 0.7112 - val_accuracy: 1.0000 - val_loss: 0.5473\n",
      "Epoch 15/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9809 - loss: 0.6810 - val_accuracy: 1.0000 - val_loss: 0.5305\n",
      "Epoch 16/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.6659 - val_accuracy: 1.0000 - val_loss: 0.5183\n",
      "Epoch 17/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.6569 - val_accuracy: 1.0000 - val_loss: 0.5054\n",
      "Epoch 18/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9755 - loss: 0.6508 - val_accuracy: 1.0000 - val_loss: 0.4935\n",
      "Epoch 19/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.6124 - val_accuracy: 1.0000 - val_loss: 0.4818\n",
      "Epoch 20/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9812 - loss: 0.6180 - val_accuracy: 1.0000 - val_loss: 0.4728\n",
      "Epoch 21/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.6114 - val_accuracy: 1.0000 - val_loss: 0.4662\n",
      "Epoch 22/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9736 - loss: 0.6034 - val_accuracy: 1.0000 - val_loss: 0.4561\n",
      "Epoch 23/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9879 - loss: 0.5840 - val_accuracy: 1.0000 - val_loss: 0.4518\n",
      "Epoch 24/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9880 - loss: 0.5720 - val_accuracy: 1.0000 - val_loss: 0.4413\n",
      "Epoch 25/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9855 - loss: 0.5554 - val_accuracy: 1.0000 - val_loss: 0.4336\n",
      "Epoch 26/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.5588 - val_accuracy: 1.0000 - val_loss: 0.4286\n",
      "Epoch 27/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.5552 - val_accuracy: 1.0000 - val_loss: 0.4225\n",
      "Epoch 28/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.5451 - val_accuracy: 1.0000 - val_loss: 0.4148\n",
      "Epoch 29/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.5334 - val_accuracy: 1.0000 - val_loss: 0.4091\n",
      "Epoch 30/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9794 - loss: 0.5564 - val_accuracy: 1.0000 - val_loss: 0.4070\n",
      "Epoch 31/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.5246 - val_accuracy: 1.0000 - val_loss: 0.4011\n",
      "Epoch 32/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.5268 - val_accuracy: 1.0000 - val_loss: 0.3950\n",
      "Epoch 33/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.5203 - val_accuracy: 1.0000 - val_loss: 0.3899\n",
      "Epoch 34/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9870 - loss: 0.5076 - val_accuracy: 1.0000 - val_loss: 0.3839\n",
      "Epoch 35/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.5008 - val_accuracy: 1.0000 - val_loss: 0.3806\n",
      "Epoch 36/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.5093 - val_accuracy: 1.0000 - val_loss: 0.3760\n",
      "Epoch 37/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.5098 - val_accuracy: 1.0000 - val_loss: 0.3710\n",
      "Epoch 38/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.4891 - val_accuracy: 1.0000 - val_loss: 0.3687\n",
      "Epoch 39/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.4762 - val_accuracy: 1.0000 - val_loss: 0.3644\n",
      "Epoch 40/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.4745 - val_accuracy: 1.0000 - val_loss: 0.3601\n",
      "Epoch 41/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.4779 - val_accuracy: 1.0000 - val_loss: 0.3578\n",
      "Epoch 42/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.4783 - val_accuracy: 1.0000 - val_loss: 0.3552\n",
      "Epoch 43/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.4593 - val_accuracy: 1.0000 - val_loss: 0.3510\n",
      "Epoch 44/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.4503 - val_accuracy: 1.0000 - val_loss: 0.3467\n",
      "Epoch 45/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.4603 - val_accuracy: 1.0000 - val_loss: 0.3423\n",
      "Epoch 46/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9807 - loss: 0.4669 - val_accuracy: 1.0000 - val_loss: 0.3408\n",
      "Epoch 47/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.4682 - val_accuracy: 1.0000 - val_loss: 0.3409\n",
      "Epoch 48/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.4504 - val_accuracy: 1.0000 - val_loss: 0.3365\n",
      "Epoch 49/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.4534 - val_accuracy: 1.0000 - val_loss: 0.3352\n",
      "Epoch 50/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.4513 - val_accuracy: 1.0000 - val_loss: 0.3331\n",
      "Epoch 51/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.4452 - val_accuracy: 1.0000 - val_loss: 0.3255\n",
      "Epoch 52/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.4320 - val_accuracy: 1.0000 - val_loss: 0.3233\n",
      "Epoch 53/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.4355 - val_accuracy: 1.0000 - val_loss: 0.3233\n",
      "Epoch 54/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.4270 - val_accuracy: 1.0000 - val_loss: 0.3193\n",
      "Epoch 55/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.4178 - val_accuracy: 1.0000 - val_loss: 0.3158\n",
      "Epoch 56/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.4246 - val_accuracy: 1.0000 - val_loss: 0.3144\n",
      "Epoch 57/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.4186 - val_accuracy: 1.0000 - val_loss: 0.3107\n",
      "Epoch 58/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.4157 - val_accuracy: 1.0000 - val_loss: 0.3071\n",
      "Epoch 59/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.4271 - val_accuracy: 1.0000 - val_loss: 0.3109\n",
      "Epoch 60/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.4155 - val_accuracy: 1.0000 - val_loss: 0.3052\n",
      "Epoch 61/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9837 - loss: 0.4250 - val_accuracy: 1.0000 - val_loss: 0.3065\n",
      "Epoch 62/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.4243 - val_accuracy: 1.0000 - val_loss: 0.3024\n",
      "Epoch 63/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.4154 - val_accuracy: 1.0000 - val_loss: 0.3005\n",
      "Epoch 64/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.3880 - val_accuracy: 1.0000 - val_loss: 0.2980\n",
      "Epoch 65/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.3904 - val_accuracy: 1.0000 - val_loss: 0.2953\n",
      "Epoch 66/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.4028 - val_accuracy: 1.0000 - val_loss: 0.2945\n",
      "Epoch 67/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9937 - loss: 0.3964 - val_accuracy: 1.0000 - val_loss: 0.2935\n",
      "Epoch 68/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.3903 - val_accuracy: 1.0000 - val_loss: 0.2877\n",
      "Epoch 69/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.3821 - val_accuracy: 1.0000 - val_loss: 0.2848\n",
      "Epoch 70/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.3879 - val_accuracy: 1.0000 - val_loss: 0.2857\n",
      "Epoch 71/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.3876 - val_accuracy: 1.0000 - val_loss: 0.2850\n",
      "Epoch 72/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9900 - loss: 0.3866 - val_accuracy: 1.0000 - val_loss: 0.2828\n",
      "Epoch 73/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9941 - loss: 0.3759 - val_accuracy: 1.0000 - val_loss: 0.2808\n",
      "Epoch 74/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.3865 - val_accuracy: 1.0000 - val_loss: 0.2784\n",
      "Epoch 75/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.3802 - val_accuracy: 1.0000 - val_loss: 0.2793\n",
      "Epoch 76/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9933 - loss: 0.3800 - val_accuracy: 1.0000 - val_loss: 0.2790\n",
      "Epoch 77/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9879 - loss: 0.3795 - val_accuracy: 1.0000 - val_loss: 0.2751\n",
      "Epoch 78/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.3767 - val_accuracy: 1.0000 - val_loss: 0.2767\n",
      "Epoch 79/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9971 - loss: 0.3611 - val_accuracy: 1.0000 - val_loss: 0.2704\n",
      "Epoch 80/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.3637 - val_accuracy: 1.0000 - val_loss: 0.2688\n",
      "Epoch 81/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.3588 - val_accuracy: 1.0000 - val_loss: 0.2667\n",
      "Epoch 82/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.3663 - val_accuracy: 1.0000 - val_loss: 0.2677\n",
      "Epoch 83/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.3689 - val_accuracy: 1.0000 - val_loss: 0.2653\n",
      "Epoch 84/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.3616 - val_accuracy: 1.0000 - val_loss: 0.2645\n",
      "Epoch 85/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.3704 - val_accuracy: 1.0000 - val_loss: 0.2650\n",
      "Epoch 86/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.3597 - val_accuracy: 1.0000 - val_loss: 0.2619\n",
      "Epoch 87/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.3552 - val_accuracy: 1.0000 - val_loss: 0.2613\n",
      "Epoch 88/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.3653 - val_accuracy: 1.0000 - val_loss: 0.2615\n",
      "Epoch 89/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.3646 - val_accuracy: 1.0000 - val_loss: 0.2567\n",
      "Epoch 90/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9951 - loss: 0.3470 - val_accuracy: 1.0000 - val_loss: 0.2588\n",
      "Epoch 91/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.3501 - val_accuracy: 1.0000 - val_loss: 0.2559\n",
      "Epoch 92/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.3613 - val_accuracy: 1.0000 - val_loss: 0.2523\n",
      "Epoch 93/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.3477 - val_accuracy: 1.0000 - val_loss: 0.2543\n",
      "Epoch 94/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.3519 - val_accuracy: 1.0000 - val_loss: 0.2550\n",
      "Epoch 95/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9929 - loss: 0.3424 - val_accuracy: 1.0000 - val_loss: 0.2496\n",
      "Epoch 96/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.3398 - val_accuracy: 1.0000 - val_loss: 0.2453\n",
      "Epoch 97/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.3413 - val_accuracy: 1.0000 - val_loss: 0.2497\n",
      "Epoch 98/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.3404 - val_accuracy: 1.0000 - val_loss: 0.2445\n",
      "Epoch 99/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9874 - loss: 0.3333 - val_accuracy: 1.0000 - val_loss: 0.2435\n",
      "Epoch 100/100\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.3307 - val_accuracy: 1.0000 - val_loss: 0.2420\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=64,\n",
    "    epochs=100,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ovqUF7-Ka-r1"
   },
   "outputs": [],
   "source": [
    "def predecir_emocion(texto, umbral_confianza=0.65):\n",
    "    texto_limpio = limpiar_texto(texto)\n",
    "    texto_vector = vectorizer.transform([texto_limpio]).toarray()\n",
    "    prediccion = model.predict(texto_vector, verbose=0)\n",
    "    \n",
    "    if np.max(prediccion) < umbral_confianza:\n",
    "        return \"indefinido\", np.max(prediccion)\n",
    "    \n",
    "    return label_encoder.inverse_transform([np.argmax(prediccion)])[0], np.max(prediccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_respuesta(texto):\n",
    "    emocion, confianza = predecir_emocion(texto)\n",
    "    \n",
    "    recursos = {\n",
    "        \"tristeza\": {\n",
    "            \"mensaje\": \"🔵 Pareces sentir tristeza. Te recomiendo:\",\n",
    "            \"acciones\": [\n",
    "                \"Meditación guiada 'Alivio emocional' (10 min)\",\n",
    "                \"Ejercicio: Escribe una carta para liberar emociones\"\n",
    "            ]\n",
    "        },\n",
    "        \"ansiedad\": {\n",
    "            \"mensaje\": \"🟠 Detecto señales de ansiedad. Prueba:\",\n",
    "            \"acciones\": [\n",
    "                \"Técnica de respiración 4-7-8 (instrucciones)\",\n",
    "                \"Ejercicio de grounding: 5-4-3-2-1\"\n",
    "            ]\n",
    "        },\n",
    "        \"estrés\": {\n",
    "            \"mensaje\": \"🟢 Sugerencias para manejar el estrés:\",\n",
    "            \"acciones\": [\n",
    "                \"Meditación 'Libera tensiones' (15 min)\",\n",
    "                \"Prioriza tareas con matriz Eisenhower\"\n",
    "            ]\n",
    "        },\n",
    "        \"enojo\": {\n",
    "            \"mensaje\": \"🔴 Detecto frustración. Intenta:\",\n",
    "            \"acciones\": [\n",
    "                \"Ejercicio físico de alta intensidad\",\n",
    "                \"Técnica de pausa consciente de 5 minutos\"\n",
    "            ]\n",
    "        },\n",
    "        \"felicidad\": {\n",
    "            \"mensaje\": \"🟡 ¡Me alegra verte así! Mantén esto:\",\n",
    "            \"acciones\": [\n",
    "                \"Registra este momento en tu diario positivo\",\n",
    "                \"Comparte tu estado con alguien especial\"\n",
    "            ]\n",
    "        },\n",
    "        \"indefinido\": {\n",
    "            \"mensaje\": \"⚪️ Necesito entenderte mejor. ¿Podrías:\",\n",
    "            \"acciones\": [\n",
    "                \"Describir cómo te sientes con más detalle?\",\n",
    "                \"Contarme qué ha pasado recientemente?\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    respuesta = recursos.get(emocion, recursos[\"indefinido\"])\n",
    "    return (\n",
    "        f\"{respuesta['mensaje']}\\n\" + \n",
    "        \"\\n\".join([f\"- {accion}\" for accion in respuesta['acciones']]) + \n",
    "        f\"\\n\\nConfianza del modelo: {confianza:.2%}\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "FdZpptV0bA4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧑 Usuario: No tengo ganas de salir de la cama hoy\n",
      "🤖 Chatbot:\n",
      "🟠 Detecto señales de ansiedad. Prueba:\n",
      "- Técnica de respiración 4-7-8 (instrucciones)\n",
      "- Ejercicio de grounding: 5-4-3-2-1\n",
      "\n",
      "Confianza del modelo: 70.60%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "🧑 Usuario: Estoy harto de las reuniones inútiles\n",
      "🤖 Chatbot:\n",
      "🔴 Detecto frustración. Intenta:\n",
      "- Ejercicio físico de alta intensidad\n",
      "- Técnica de pausa consciente de 5 minutos\n",
      "\n",
      "Confianza del modelo: 89.11%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "🧑 Usuario: Me palpita el corazón muy rápido\n",
      "🤖 Chatbot:\n",
      "⚪️ Necesito entenderte mejor. ¿Podrías:\n",
      "- Describir cómo te sientes con más detalle?\n",
      "- Contarme qué ha pasado recientemente?\n",
      "\n",
      "Confianza del modelo: 29.02%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "🧑 Usuario: Logré terminar todos mis pendientes a tiempo!\n",
      "🤖 Chatbot:\n",
      "⚪️ Necesito entenderte mejor. ¿Podrías:\n",
      "- Describir cómo te sientes con más detalle?\n",
      "- Contarme qué ha pasado recientemente?\n",
      "\n",
      "Confianza del modelo: 53.54%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n",
      "🧑 Usuario: El tráfico me hizo llegar tarde otra vez\n",
      "🤖 Chatbot:\n",
      "🟢 Sugerencias para manejar el estrés:\n",
      "- Meditación 'Libera tensiones' (15 min)\n",
      "- Prioriza tareas con matriz Eisenhower\n",
      "\n",
      "Confianza del modelo: 79.29%\n",
      "\n",
      "――――――――――――――――――――――――――――――――――――――――――――――――――\n"
     ]
    }
   ],
   "source": [
    "test_cases = [\n",
    "    \"No tengo ganas de salir de la cama hoy\",\n",
    "    \"Estoy harto de las reuniones inútiles\",\n",
    "    \"Me palpita el corazón muy rápido\",\n",
    "    \"Logré terminar todos mis pendientes a tiempo!\",\n",
    "    \"El tráfico me hizo llegar tarde otra vez\"\n",
    "]\n",
    "\n",
    "for caso in test_cases:\n",
    "    print(f\"🧑 Usuario: {caso}\")\n",
    "    print(f\"🤖 Chatbot:\\n{chatbot_respuesta(caso)}\\n\")\n",
    "    print(\"―\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
